{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edc50c6f",
   "metadata": {},
   "source": [
    "### Step 1: Load train_preprocessed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e31cc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 21215 rows from train_preprocessed.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>ref_id</th>\n",
       "      <th>clean_context</th>\n",
       "      <th>dataset_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1002_2017jc013030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Volk and Hoffert, 1985;</td>\n",
       "      <td>Primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1002_2017jc013030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Honjo et al., 2014;</td>\n",
       "      <td>Primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1002_2017jc013030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Legendre et al., 2015</td>\n",
       "      <td>Primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1002_2017jc013030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Riser and Johnson, 2008;</td>\n",
       "      <td>Primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1002_2017jc013030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graff et al., 2012</td>\n",
       "      <td>Primary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             article_id ref_id             clean_context dataset_type\n",
       "0  10.1002_2017jc013030    NaN   Volk and Hoffert, 1985;      Primary\n",
       "1  10.1002_2017jc013030    NaN       Honjo et al., 2014;      Primary\n",
       "2  10.1002_2017jc013030    NaN     Legendre et al., 2015      Primary\n",
       "3  10.1002_2017jc013030    NaN  Riser and Johnson, 2008;      Primary\n",
       "4  10.1002_2017jc013030    NaN        Graff et al., 2012      Primary"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"train_preprocessed.csv\")\n",
    "print(f\"✅ Loaded {len(train_df)} rows from train_preprocessed.csv\")\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b46042",
   "metadata": {},
   "source": [
    "### Step 2: Encode labels and split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d42dbac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ After cleaning: Training samples: 17206, Validation samples: 1950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11019    Our previous attempts to identify putative ant...\n",
       "9236     Sequences of the E1HVR1 region of the HCV geno...\n",
       "7321                                                    2,\n",
       "13613    A further six loci identified as F ST outliers...\n",
       "17539                                                   19\n",
       "Name: clean_context, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "train_df['label'] = le.fit_transform(train_df['dataset_type'])  # Primary=0, Secondary=1\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_df['clean_context'], train_df['label'],\n",
    "    test_size=0.1, random_state=42, stratify=train_df['label']\n",
    ")\n",
    "\n",
    "# Drop rows with empty or NaN clean_context\n",
    "X_train = X_train[X_train.notnull()]\n",
    "y_train = y_train[X_train.index]\n",
    "\n",
    "X_val = X_val[X_val.notnull()]\n",
    "y_val = y_val[X_val.index]\n",
    "\n",
    "print(f\"✅ After cleaning: Training samples: {len(X_train)}, Validation samples: {len(X_val)}\")\n",
    "\n",
    "# Optional: display first few training samples\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3b7e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ After removing short/numeric rows: Training samples: 15445, Validation samples: 1730\n"
     ]
    }
   ],
   "source": [
    "# Keep only rows with at least 3 characters and not purely numeric\n",
    "def is_valid(text):\n",
    "    text = str(text).strip()\n",
    "    return len(text) > 2 and not text.isnumeric()\n",
    "\n",
    "X_train = X_train[X_train.apply(is_valid)]\n",
    "y_train = y_train[X_train.index]\n",
    "\n",
    "X_val = X_val[X_val.apply(is_valid)]\n",
    "y_val = y_val[X_val.index]\n",
    "\n",
    "print(f\"✅ After removing short/numeric rows: Training samples: {len(X_train)}, Validation samples: {len(X_val)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c032f421",
   "metadata": {},
   "source": [
    "### Step 3: TF-IDF vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af4f07e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TF-IDF feature matrix shapes -> Train: (15445, 5000), Validation: (1730, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "\n",
    "# Fit on training data and transform both training and validation sets\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "\n",
    "print(f\"✅ TF-IDF feature matrix shapes -> Train: {X_train_tfidf.shape}, Validation: {X_val_tfidf.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bef18f3",
   "metadata": {},
   "source": [
    "### Step 4: Train baseline classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9219afe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Baseline Accuracy: 0.9104, F1-score: 0.8283\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Primary       0.89      0.99      0.94      1210\n",
      "   Secondary       0.98      0.72      0.83       520\n",
      "\n",
      "    accuracy                           0.91      1730\n",
      "   macro avg       0.93      0.86      0.88      1730\n",
      "weighted avg       0.92      0.91      0.91      1730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Initialize and train Logistic Regression\n",
    "clf = LogisticRegression(max_iter=500)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = clf.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluate performance\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "print(f\"✅ Baseline Accuracy: {acc:.4f}, F1-score: {f1:.4f}\\n\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_pred, target_names=le.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
